<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="author" content="Ganesh Kinkar Giri" /><link rel="canonical" href="https://ganesh-document.github.io/all-documents/AIML/RAG/Retrieval_augmented_generation.html" />
      <link rel="shortcut icon" href="../../img/favicon.ico" />
    <title>Retrieval Augmented Generation (RAG) - All the documents</title>
    <link rel="stylesheet" href="../../css/theme.css" />
    <link rel="stylesheet" href="../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="../../css/extra.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Retrieval Augmented Generation (RAG)";
        var mkdocs_page_input_path = "AIML/RAG/Retrieval_augmented_generation.md";
        var mkdocs_page_url = "/all-documents/AIML/RAG/Retrieval_augmented_generation.html";
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../.." class="icon icon-home"> All the documents
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Overview</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" >Documents</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../Documentsdetails.html">Documents details</a>
                </li>
    </ul>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">AIML</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../aiml-overview.html">Overview</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >NVIDIA</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" >NIM</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../NVIDIA/NIM/Code-Generation.html">Code Generation</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../NVIDIA/NIM/digital_twin.html">Digital Twin</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../NVIDIA/NIM/dna_sequencing.html">DNA Sequencing</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../NVIDIA/NIM/drug_discovery.html">Drug Discovery</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../NVIDIA/NIM/image_classification.html">Image Classification</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../NVIDIA/NIM/image_generation.html">Image Generation</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../NVIDIA/NIM/image_to_360.html">Image To 360</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../NVIDIA/NIM/image_to_embedding.html">Image To Embedding</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../NVIDIA/NIM/image_to_text.html">Image To Text</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../NVIDIA/NIM/medical_imaging.html">Medical Imaging</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../NVIDIA/NIM/object_detect.html">Object Detect</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../NVIDIA/NIM/optical_character_recog.html">Optical Character Recognition</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../NVIDIA/NIM/rag.html">Retrieval Augmented Generation</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../NVIDIA/NIM/speech_to_animation.html">Speech To Animation</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../NVIDIA/NIM/speech_to_text.html">Speech To Text</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../NVIDIA/NIM/sdg.html">Synthetic Data Generation</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../NVIDIA/NIM/text_translation.html">Text Translation</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../NVIDIA/NIM/text_to_360.html">Text To 360</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../NVIDIA/NIM/text_to_embedding.html">Text To Embedding</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../NVIDIA/NIM/text_to_image.html">Text To Image</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../NVIDIA/NIM/text_to_speech.html">Text To Speech</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../NVIDIA/NIM/weather_simulation.html">Weather Simulation</a>
                </li>
    </ul>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Supervised</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../Supervised/Supervised-overview.html">Supervised Overview</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Regression</a>
    <ul>
                <li class="toctree-l3"><a class="" href="../Supervised/Linear-Regression.md">Linear Regression</a>
                </li>
                <li class="toctree-l3"><a class="" href="../Supervised/Decision-Tree.md">Decision Tree</a>
                </li>
                <li class="toctree-l3"><a class="" href="../Supervised/Random-Forest.md">Random Forest</a>
                </li>
                <li class="toctree-l3"><a class="" href="../Supervised/SVM.md">SVM</a>
                </li>
                <li class="toctree-l3"><a class="" href="../Supervised/Naive-Bayes.md">Naive Bayes</a>
                </li>
                <li class="toctree-l3"><a class="" href="../Supervised/Gradient-Boosting.md">Gradient Boosting</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Classification</a>
    <ul>
                <li class="toctree-l3"><a class="" href="../Supervised/Classification-overview.md">Classification Overview</a>
                </li>
                <li class="toctree-l3"><a class="" href="../Supervised/Logistic-Regression.md">Logistic Regression</a>
                </li>
                <li class="toctree-l3"><a class="" href="../Supervised/KNN.md">KNN</a>
                </li>
    </ul>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Unsupervised</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../Unsupervised/Unsupervised-overview.html">Unsupervised Overview</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../Unsupervised/K-means.html">K-means</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../Unsupervised/PCA.html">PCA</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../Unsupervised/SOM.html">SOM</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../Unsupervised/ARIMA.html">ARIMA</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../Unsupervised/SARIMA.html">SARIMA</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Deep Learning</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../DeepLearning/DeepLearning-overview.html">Deep Learning Overview</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../DeepLearning/DeepLearning-algorithms.html">Deep Learning Algorithms</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../DeepLearning/Keras.html">Keras</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../DeepLearning/Tensorflow.html">Tensorflow</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../DeepLearning/Pytorch.html">Pytorch</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../DeepLearning/LSTM.html">LSTM</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../DeepLearning/Autoencoder.html">Autoencoder</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../DeepLearning/Reinforcement-Learning.html">Reinforcement Learning</a>
                </li>
                <li class="toctree-l2"><a class="" href="../DeepLearning/NLP.md">NLP</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../DeepLearning/BERT.html">BERT</a>
                </li>
                <li class="toctree-l2"><a class="" href="../DeepLearning/GPT.md">GPT</a>
                </li>
    </ul>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../..">All the documents</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../.." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">Retrieval Augmented Generation (RAG)</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/tree/main/all-documents/AIML/RAG/Retrieval_augmented_generation.md">Edit on Ganesh All Documents</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="retrieval-augmented-generation-rag"><strong>Retrieval Augmented Generation (RAG)</strong><a class="headerlink" href="#retrieval-augmented-generation-rag" title="Permanent link">#</a></h1>
<p>But we have another approach where we can augment the knowledge of LLMs and retrieve information from custom content.It is called Retrieval Augmented Generation (RAG).</p>
<p>Utility tools like ChatPDF have been popular Generative AI tools. The PDF document is connected as an external data source and we can interact with it as we are assisted by an LLM.</p>
<p>What we do in RAG is inserting additional data into the context (prompt) of a model at inference time. That helps the LLM get more precise and relevant content for our queries when compared to zero-shot prompting.</p>
<p>Another way of looking at it is in the context of a doctor and patient. A doctor’s diagnosis can be significantly more precise and accurate when they have access to the patient’s test results and charts, as opposed to relying solely on symptomatic observations.</p>
<p><img alt="RAG" src="image/image12.png" /></p>
<p><img alt="RAG" src="image/image14.png" />
<img alt="RAG" src="image/image15.png" /></p>
<p><strong>The workflow of the RAG based LLM application will be as follows:</strong></p>
<ol>
<li>Receive query from the user.</li>
<li>Convert it to an embedded query vector preserving the semantics, using an embedding model.</li>
<li>Retrieve the top-k relevant content from the vector database by computing similarity between the query embedding and the content embedding in the database.</li>
<li>Pass the retrieved content and query as a prompt to an LLM.</li>
<li>The LLM gives the required response.</li>
</ol>
<p><img alt="RAG" src="image/image13.png" /></p>
<ol>
<li>
<p>Download Ollama(Macos)
   https://ollama.com/download
   https://github.com/ollama/ollama</p>
</li>
<li>
<p>Unzip the zip file</p>
</li>
<li>Move to Application </li>
</ol>
<pre><code>(base) gggggggg:~ ganesh$ ollama
Usage:
  ollama [flags]
  ollama [command]

Available Commands:
  serve       Start ollama
  create      Create a model from a Modelfile
  show        Show information for a model
  run         Run a model
  stop        Stop a running model
  pull        Pull a model from a registry
  push        Push a model to a registry
  list        List models
  ps          List running models
  cp          Copy a model
  rm          Remove a model
  help        Help about any command

Flags:
  -h, --help      help for ollama
  -v, --version   Show version information

Use &quot;ollama [command] --help&quot; for more information about a command.
(base) ggggggggg:~ ganesh$ 
</code></pre>
<ol>
<li>Run the llama2</li>
</ol>
<pre><code>(base) gggggg:~ ganesh$ ollama run llama2
pulling manifest 
pulling 8934d96d3f08... 100% ▕██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏ 3.8 GB                         
pulling 8c17c2ebb0ea... 100% ▕██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏ 7.0 KB                         
pulling 7c23fb36d801... 100% ▕██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏ 4.8 KB                         
pulling 2e0493f67d0c... 100% ▕██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏   59 B                         
pulling fa304d675061... 100% ▕██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏   91 B                         
pulling 42ba7f8a01dd... 100% ▕██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏  557 B                         
verifying sha256 digest 
writing manifest 
success 
&gt;&gt;&gt; 
&gt;&gt;&gt; Send a message (/? for help)


</code></pre>
<h1 id="rag-pipeline-with-vector-database">RAG Pipeline with Vector DataBase<a class="headerlink" href="#rag-pipeline-with-vector-database" title="Permanent link">#</a></h1>
<pre><code>## Data Ingetion
#pip install pypdf
#pip install langchain_community
from langchain_community.document_loaders import TextLoader
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.document_loaders import WebBaseLoader
from langchain_community.document_loaders import CSVLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document
#from bs4 import SoupStrainer
import bs4
import os
from dotenv import load_dotenv
</code></pre>
<pre><code>load_dotenv()
os.environ['OPENAPI_API_KEY']=os.getenv(&quot;OPENAPI_API_KEY&quot;)
</code></pre>
<pre><code>Text reader
loader = TextLoader('Speech.txt')
docs = loader.load()
</code></pre>
<pre><code>for doc in docs:
    print(doc.page_content)  # or any other attribute like `metadata`
</code></pre>
<pre><code>#Web based loader
#Load, chunk and Index the content of HTML page

loader = WebBaseLoader(web_paths=(&quot;https://lilianweng.github.io/posts/2023-06-23-agent/&quot;,),\
                                   bs_kwargs=dict(parse_only=bs4.SoupStrainer( \
                                   class_=(&quot;post-title&quot;,&quot;post-content&quot;,&quot;post-header&quot;)
                                 )))

docs=loader.load()
</code></pre>
<pre><code>for doc in docs:
    print(doc.page_content)  # or any other attribute like `metadata`
</code></pre>
<pre><code># PDF Reader
loader = PyPDFLoader('docs/Ganesh_Kinkar_Giri_DevSecOps.pdf')
docs = loader.load()
</code></pre>
<pre><code>for doc in docs:
    print(doc.page_content)  # or any other attribute like `metadata`
</code></pre>
<pre><code>#CSV Loader
loader = CSVLoader(&quot;issue.csv&quot;)
docs = loader.load()
</code></pre>
<pre><code>for doc in docs:
    print(doc.page_content)  # or any other attribute like `metadata`
</code></pre>
<h1 id="chunk-split-the-text-data">Chunk &amp; Split the text data<a class="headerlink" href="#chunk-split-the-text-data" title="Permanent link">#</a></h1>
<pre><code>text_splitter = RecursiveCharacterTextSplitter(chunk_size=200,chunk_overlap=50)
chunk_documents = text_splitter.split_documents(docs)
chunk_documents
</code></pre>
<h1 id="vector-embedding-and-vector-store">Vector Embedding and Vector Store<a class="headerlink" href="#vector-embedding-and-vector-store" title="Permanent link">#</a></h1>
<h2 id="either-you-can-use-embeddings-model-openai-or-ollama">Either you can use Embeddings model OpenAI or ollama<a class="headerlink" href="#either-you-can-use-embeddings-model-openai-or-ollama" title="Permanent link">#</a></h2>
<pre><code>from langchain_openai import OpenAIEmbeddings
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.vectorstores import FAISS

db=FAISS.from_documents(chunk_documents,OllamaEmbeddings())
db
</code></pre>
<h1 id="query">Query<a class="headerlink" href="#query" title="Permanent link">#</a></h1>
<pre><code>query = &quot;unable to connect VM/ VM not accessible&quot;
retrive_result = db.similarity_search(query)
print(retrive_result[0].page_content)
</code></pre>
<h1 id="retirever-and-chain-with-langchain">Retirever and Chain with Langchain<a class="headerlink" href="#retirever-and-chain-with-langchain" title="Permanent link">#</a></h1>
<pre><code>## Data Ingetion
#pip install pypdf
#pip install langchain_community
from langchain_community.document_loaders import TextLoader
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.document_loaders import WebBaseLoader
from langchain_community.document_loaders import CSVLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document
#from bs4 import SoupStrainer
import bs4
import os
from dotenv import load_dotenv
</code></pre>
<pre><code>load_dotenv()
os.environ['OPENAPI_API_KEY']=os.getenv(&quot;OPENAPI_API_KEY&quot;)
</code></pre>
<pre><code>#Text Loader
loader = TextLoader(&quot;issue.txt&quot;)
docs = loader.load()
docs
</code></pre>
<h1 id="chunk-split-the-text-data_1">Chunk &amp; Split the text data<a class="headerlink" href="#chunk-split-the-text-data_1" title="Permanent link">#</a></h1>
<pre><code>text_splitter = RecursiveCharacterTextSplitter(chunk_size=200,chunk_overlap=50)
chunk_documents = text_splitter.split_documents(docs)
chunk_documents
</code></pre>
<h1 id="vector-embedding-and-vector-store_1">Vector Embedding and Vector Store<a class="headerlink" href="#vector-embedding-and-vector-store_1" title="Permanent link">#</a></h1>
<h2 id="either-you-can-use-embeddings-model-openai-or-ollama_1">Either you can use Embeddings model OpenAI or ollama<a class="headerlink" href="#either-you-can-use-embeddings-model-openai-or-ollama_1" title="Permanent link">#</a></h2>
<pre><code>from langchain_openai import OpenAIEmbeddings
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.vectorstores import FAISS

db=FAISS.from_documents(chunk_documents,OllamaEmbeddings())
db
</code></pre>
<h1 id="design-chatprompt-template">Design ChatPrompt Template<a class="headerlink" href="#design-chatprompt-template" title="Permanent link">#</a></h1>
<pre><code>from langchain_core.prompts import ChatPromptTemplate
prompt=ChatPromptTemplate.from_template(&quot;&quot;&quot;
Answer the following question based only on the provided context.
Think step by step before providing a detailed answer.
&lt;context&gt;
{context}                                                                                                                        
&lt;/context&gt;

Question: {input}                                                                                
&quot;&quot;&quot;)
</code></pre>
<h1 id="to-integrate-with-llm-here-will-use-opensource-llmollama-model-llama2">To integrate with LLM - here will use opensource LLM(Ollama) model llama2<a class="headerlink" href="#to-integrate-with-llm-here-will-use-opensource-llmollama-model-llama2" title="Permanent link">#</a></h1>
<pre><code>from langchain_community.llms import Ollama

llm=Ollama(model=&quot;llama2&quot;)
llm
</code></pre>
<h2 id="chain">Chain<a class="headerlink" href="#chain" title="Permanent link">#</a></h2>
<pre><code>from langchain.chains.combine_documents import create_stuff_documents_chain
document_chain = create_stuff_documents_chain(llm, prompt)
document_chain
</code></pre>
<h2 id="retrievers">Retrievers<a class="headerlink" href="#retrievers" title="Permanent link">#</a></h2>
<pre><code>retrievers = db.as_retriever()
retrievers
</code></pre>
<h2 id="retrievers-chain">Retrievers chain<a class="headerlink" href="#retrievers-chain" title="Permanent link">#</a></h2>
<pre><code>from langchain.chains import create_retrieval_chain
retrieval_chain = create_retrieval_chain(retrievers, document_chain)
</code></pre>
<pre><code>import textwrap
response = retrieval_chain.invoke({&quot;input&quot;:&quot;Low disk space&quot;})
formatted_answer = textwrap.fill(response['answer'], width=80)
#wrapped_text = &quot;\n\n&quot;.join(textwrap.fill(paragraph, width=80) for paragraph in formatted_answer.split(&quot;\n\n&quot;))
#print(wrapped_text)
print(formatted_answer)
</code></pre>
<h2 id="ans">Ans:<a class="headerlink" href="#ans" title="Permanent link">#</a></h2>
<pre><code>Based on the provided context, the answer to the question &quot;Low disk space&quot; is:
To resolve low disk space issues, the team should first check which application
is using the most disk space by running the command `df -h` in the terminal.
This will display a list of all mounted file systems and their usage in
percentage. The application that is using the most disk space should be
identified and the team should then take steps to free up space for that
application.  One possible solution is to increase the SKU size for the
application by running the command `sudoedit /etc/systemd/multi-
user/sockets.d/skusize` and updating the value of `SKU_SIZE` to a larger value.
This will allow the application to use more disk space without running out of
space.  Another solution is to clean up any unnecessary files or data that are
taking up space on the system by using the command `gzip -d &lt;filename&gt;` to
decompress files and then removing them with the command `rm &lt;filename&gt;`. This
will free up space on the disk without affecting the application's
functionality.  The team should also consider optimizing the application's code
to reduce its dependencies on disk space, such as by using caching or other
memory-based storage solutions. This may involve working with the application's
developers to make changes to the application's architecture.  Finally, the team
can check if there are any other applications that are using excessive amounts
of disk space and take steps to free up space for those applications as well.
</code></pre>
              
            </div>
          </div><footer>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/ganesh-document/all-documents" class="fa fa-code-fork" style="color: #fcfcfc"> Ganesh All Documents</a>
        </span>
    
    
    
  </span>
</div>
    <script src="../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../..";</script>
    <script src="../../js/theme_extra.js"></script>
    <script src="../../js/theme.js"></script>
      <script src="../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
