<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="author" content="Ganesh Kinkar Giri" /><link rel="canonical" href="https://ganesh-document.github.io/all-documents/NVIDIA/NIM/Models/LLM-Models/google/google.html" />
      <link rel="shortcut icon" href="../../../../../img/favicon.ico" />
    <title>google - All the documents</title>
    <link rel="stylesheet" href="../../../../../css/theme.css" />
    <link rel="stylesheet" href="../../../../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="../../../../../css/extra.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "google";
        var mkdocs_page_input_path = "NVIDIA/NIM/Models/LLM-Models/google/google.md";
        var mkdocs_page_url = "/all-documents/NVIDIA/NIM/Models/LLM-Models/google/google.html";
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../../../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../../../../.." class="icon icon-home"> All the documents
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Overview</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" >Documents</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../../../../Documentsdetails.html">Documents details</a>
                </li>
    </ul>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">AIML</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../../../../../AIML/aiml-overview.html">Overview</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" >NVIDIA</a>
    <ul class="current">
                <li class="toctree-l2 current"><a class="reference internal current" >NIM Models</a>
    <ul class="current">
                <li class="toctree-l3 current"><a class="reference internal current" >Large Language Models</a>
    <ul class="current">
                <li class="toctree-l4"><a class="reference internal" href="../01-ai/01-ai-yi-large.html">01-ai</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../abacusai/abacusai.html">abacusai</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../aisingapore/aisingapore.html">aisingapore</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../bigcode/bigcode.html">bigcode</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../databricks/databricks.html">databricks</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../deepseek/deepseek.html">deepseek</a>
                </li>
                <li class="toctree-l4 current"><a class="reference internal current" href="#">google</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../ibm/ibm.html">ibm</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../mediatek/mediatek.html">mediatek</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../meta/meta.html">meta</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../microsoft/microsoft.html">microsoft</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../mistralai/mistralai.html">mistralai</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../nvidia/nvidia.html">nvidia</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../qwen/qwen.html">qwen</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../rakuten/rakuten.html">rakuten</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../seallms/seallms.html">seallms</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../snowflake/snowflake.html">snowflake</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../upstage/upstage.html">upstage</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Retrieval Models</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Retrieval-Models/baai.html">baai</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Retrieval-Models/nvidia.html">nvidia</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Retrieval-Models/snowflake.html">snowflake</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Visual Models</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Visual-Models/briaai.html">briaai</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Visual-Models/nvidia.html">nvidia</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Visual-Models/stabilityai.html">stabilityai</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Multimodal Models</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Multimodal-Models/adept.html">adept</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Multimodal-Models/google.html">google</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Multimodal-Models/liuhaotian.html">liuhaotian</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Multimodal-Models/microsoft.html">microsoft</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Multimodal-Models/nvidia.html">nvidia</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Healthcare Models</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Healthcare-Models/deepmind.html">deepmind</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Healthcare-Models/ipd.html">ipd</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Healthcare-Models/meta.html">meta</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Healthcare-Models/mit.html">mit</a>
                </li>
                <li class="toctree-l4"><a class="reference internal" href="../../Healthcare-Models/nvidia.html">nvidia</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Route Optimization Models</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Route-Optimization-Models/nvidia.html">nvidia</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" >Climate Simulation Models</a>
    <ul>
                <li class="toctree-l4"><a class="reference internal" href="../../Route-Climate-Simulation-Models/nvidia.html">nvidia</a>
                </li>
    </ul>
                </li>
    </ul>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Supervised</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../../../../AIML/Supervised/Supervised-overview.html">Supervised Overview</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Regression</a>
    <ul>
                <li class="toctree-l3"><a class="" href="../../../../../AIML/Supervised/Linear-Regression.md">Linear Regression</a>
                </li>
                <li class="toctree-l3"><a class="" href="../../../../../AIML/Supervised/Decision-Tree.md">Decision Tree</a>
                </li>
                <li class="toctree-l3"><a class="" href="../../../../../AIML/Supervised/Random-Forest.md">Random Forest</a>
                </li>
                <li class="toctree-l3"><a class="" href="../../../../../AIML/Supervised/SVM.md">SVM</a>
                </li>
                <li class="toctree-l3"><a class="" href="../../../../../AIML/Supervised/Naive-Bayes.md">Naive Bayes</a>
                </li>
                <li class="toctree-l3"><a class="" href="../../../../../AIML/Supervised/Gradient-Boosting.md">Gradient Boosting</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Classification</a>
    <ul>
                <li class="toctree-l3"><a class="" href="../../../../../AIML/Supervised/Classification-overview.md">Classification Overview</a>
                </li>
                <li class="toctree-l3"><a class="" href="../../../../../AIML/Supervised/Logistic-Regression.md">Logistic Regression</a>
                </li>
                <li class="toctree-l3"><a class="" href="../../../../../AIML/Supervised/KNN.md">KNN</a>
                </li>
    </ul>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Unsupervised</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../../../../AIML/Unsupervised/Unsupervised-overview.html">Unsupervised Overview</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../../../AIML/Unsupervised/K-means.html">K-means</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../../../AIML/Unsupervised/PCA.html">PCA</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../../../AIML/Unsupervised/SOM.html">SOM</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../../../AIML/Unsupervised/ARIMA.html">ARIMA</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../../../AIML/Unsupervised/SARIMA.html">SARIMA</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Deep Learning</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../../../../AIML/DeepLearning/DeepLearning-overview.html">Deep Learning Overview</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../../../AIML/DeepLearning/DeepLearning-algorithms.html">Deep Learning Algorithms</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../../../AIML/DeepLearning/Keras.html">Keras</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../../../AIML/DeepLearning/Tensorflow.html">Tensorflow</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../../../AIML/DeepLearning/Pytorch.html">Pytorch</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../../../AIML/DeepLearning/LSTM.html">LSTM</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../../../AIML/DeepLearning/Autoencoder.html">Autoencoder</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../../../AIML/DeepLearning/Reinforcement-Learning.html">Reinforcement Learning</a>
                </li>
                <li class="toctree-l2"><a class="" href="../../../../../AIML/DeepLearning/NLP.md">NLP</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../../../AIML/DeepLearning/BERT.html">BERT</a>
                </li>
                <li class="toctree-l2"><a class="" href="../../../../../AIML/DeepLearning/GPT.md">GPT</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >RAG</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../../../../AIML/RAG/vector_database.html">Vector Database</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../../../AIML/RAG/Retrieval_augmented_generation.html">Retrieval augmented generation</a>
                </li>
    </ul>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../..">All the documents</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../../../.." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">AIML</li>
          <li class="breadcrumb-item">NVIDIA</li>
          <li class="breadcrumb-item">NIM Models</li>
          <li class="breadcrumb-item">Large Language Models</li>
      <li class="breadcrumb-item active">google</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/tree/main/all-documents/NVIDIA/NIM/Models/LLM-Models/google/google.md">Edit on Ganesh All Documents</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h2 id="models">Models<a class="headerlink" href="#models" title="Permanent link">#</a></h2>
<h2 id="google-gemma-2b">google / gemma-2b<a class="headerlink" href="#google-gemma-2b" title="Permanent link">#</a></h2>
<p><strong>Model Information</strong></p>
<p>Gemma is a family of lightweight, state-of-the art open models from Google,built from the same research and technology used to create the Gemini models.They are text-to-text, decoder-only large language models, available in English,with open weights, pre-trained variants, and instruction-tuned variants. Gemma models are well-suited for a variety of text generation tasks, including question answering, summarization, and reasoning. Their relatively small size makes it possible to deploy them in environments with limited resources such as a laptop, desktop or your own cloud infrastructure, democratizing access to \state of the art AI models and helping foster innovation for everyone.</p>
<h2 id="references">References:<a class="headerlink" href="#references" title="Permanent link">#</a></h2>
<p><strong>Author:</strong> Google</p>
<p><strong>Model Page:</strong> Gemma</p>
<p><a href="https://docs.api.nvidia.com/nim/reference/google-gemma-2b">google / gemma-2b Model</a>
<a href="https://docs.api.nvidia.com/nim/reference/google-gemma-2b-infer">google / gemma-2b Endpoint</a>
<a href="https://ai.google.dev/gemma/docs/model_card">Model Card</a></p>
<h2 id="resources-and-technical-documentation">Resources and Technical Documentation:<a class="headerlink" href="#resources-and-technical-documentation" title="Permanent link">#</a></h2>
<p><a href="https://ai.google.dev/responsible">Responsible Generative AI Toolkit</a>
<a href="https://www.kaggle.com/models/google/gemma">Gemma on Kaggle</a>
<a href="https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/335?pli=1">Gemma on Vertex Model Garden</a></p>
<h2 id="third-party-community-consideration">Third-Party Community Consideration<a class="headerlink" href="#third-party-community-consideration" title="Permanent link">#</a></h2>
<p>This model is not owned or developed by NVIDIA. This model has been developed and built to a third-party’s requirements for this application and use case.</p>
<p><strong>Intended Usage</strong>
Open Large Language Models (LLMs) have a wide range of applications across various industries and domains. The following list of potential uses is not comprehensive. The purpose of this list is to provide contextual information about the possible use-cases that the model creators considered as part of model training and development.</p>
<ul>
<li>Content Creation and Communication</li>
<li>Text Generation: These models can be used to generate creative text formats such as poems, scripts, code, marketing copy, and email drafts.</li>
<li>Chatbots and Conversational AI: Power conversational interfaces for customer service, virtual assistants, or interactive applications.</li>
<li>Text Summarization: Generate concise summaries of a text corpus, research papers, or reports.</li>
<li>Research and Education</li>
<li>Natural Language Processing (NLP) Research: These models can serve as a foundation for researchers to experiment with NLPtechniques, develop algorithms, and contribute to the advancement of the field.</li>
<li>Language Learning Tools: Support interactive language learning experiences, aiding in grammar correction or providing writing practice.</li>
<li>Knowledge Exploration: Assist researchers in exploring large bodies of text by generating summaries or answering questions about specific topics.</li>
</ul>
<h2 id="model-data">Model Data<a class="headerlink" href="#model-data" title="Permanent link">#</a></h2>
<p><strong>Training Dataset</strong></p>
<p>These models were trained on a text dataset that includes a wide variety of sources, totaling 6 trillion tokens. Here are the primary training data sources:</p>
<ul>
<li>Web Documents: A diverse collection of web text ensures the model is exposed to a broad range of linguistic styles, topics, and vocabulary. Primarily English-language content.</li>
<li>Code: Exposing the model to code helps it to learn the syntax and patterns of programming languages, which improves its ability to generate code or understand code-related questions.</li>
<li>Mathematics: Training on mathematical text helps the model learn logical reasoning, symbolic representation, and to address mathematical queries.</li>
</ul>
<p>The combination of these diverse data sources is crucial for training a powerful language model that can handle a wide variety of different tasks and text formats.</p>
<h2 id="data-preprocessing">Data Preprocessing<a class="headerlink" href="#data-preprocessing" title="Permanent link">#</a></h2>
<p>Here are the key data cleaning and filtering methods applied to the training data:</p>
<ul>
<li>CSAM Filtering: Rigorous CSAM (Child Sexual Abuse Material) filtering was applied at multiple stages in the data preparation process to ensure the exclusion of harmful and illegal content.</li>
<li>Sensitive Data Filtering: As part of making Gemma pre-trained models safe and reliable, automated techniques were used to filter out certain personal information and other sensitive data from training sets.</li>
<li>Additional methods: Filtering based on content quality and safely in line with our <a href="https://storage.googleapis.com/gweb-uniblog-publish-prod/documents/2023_Google_AI_Principles_Progress_Update.pdf#page=11">policies</a></li>
</ul>
<h2 id="implementation-information">Implementation Information<a class="headerlink" href="#implementation-information" title="Permanent link">#</a></h2>
<p><strong>TensorRT-LLM</strong></p>
<p>The endpoint available on NGC catalog is accelerated by TensorRT-LLM, an open-source library for optimizing inference performance. Gemma is compatible across NVIDIA AI platforms—from the datacenter, cloud, to the local PC with RTX GPU systems.  </p>
<p>Gemma models use a vocabulary size of 256K and support a context length of up to 8K while using rotary positional embedding (RoPE). With support for Position Interpolation (PI) available in TensorRT-LLM, Gemma models using RoPE can support longer output sequence lengths at inference time while retaining original model architecture. </p>
<h2 id="model-customization">Model Customization<a class="headerlink" href="#model-customization" title="Permanent link">#</a></h2>
<p>The model is converted to .nemo for easy customization with NVIDIA NeMo framework – an end-to-end framework to curate data, tune models, and deploy anywhere. It supports various customization techniques including RLHF, SFT, LoRA, and Steer-LM.</p>
<h2 id="evaluation">Evaluation<a class="headerlink" href="#evaluation" title="Permanent link">#</a></h2>
<p>Model evaluation metrics and results.</p>
<h2 id="benefits">Benefits<a class="headerlink" href="#benefits" title="Permanent link">#</a></h2>
<p>At the time of release, this family of models provides high-performance open large language model implementations designed from the ground up for Responsible AI development compared to similarly sized models.</p>
<p>Using the benchmark evaluation metrics described in this document, these models have shown to provide superior performance to other, comparably-sized open model alternatives.</p>
<h2 id="request">Request<a class="headerlink" href="#request" title="Permanent link">#</a></h2>
<pre><code>import requests

url = &quot;https://integrate.api.nvidia.com/v1/chat/completions&quot;

payload = {
    &quot;model&quot;: &quot;google/gemma-2b&quot;,
    &quot;max_tokens&quot;: 1024,
    &quot;stream&quot;: False,
    &quot;temperature&quot;: 0.5,
    &quot;top_p&quot;: 1,
    &quot;stop&quot;: None,
    &quot;frequency_penalty&quot;: 0,
    &quot;presence_penalty&quot;: 0,
    &quot;seed&quot;: 0,
    &quot;messages&quot;: &quot;string&quot;
}
headers = {
    &quot;accept&quot;: &quot;application/json&quot;,
    &quot;content-type&quot;: &quot;application/json&quot;,
    &quot;authorization&quot;: &quot;Bearer nvapi-xxxxx&quot;
}

response = requests.post(url, json=payload, headers=headers)

print(response.text)
</code></pre>
<h2 id="response">Response<a class="headerlink" href="#response" title="Permanent link">#</a></h2>
<pre><code>{
  &quot;id&quot;: &quot;chatcmpl-657cab5d-390b-47ed-bfd6-84b4d28c4396&quot;,
  &quot;object&quot;: &quot;chat.completion&quot;,
  &quot;created&quot;: 1732296663,
  &quot;model&quot;: &quot;google/gemma-2b&quot;,
  &quot;choices&quot;: [
    {
      &quot;index&quot;: 0,
      &quot;message&quot;: {
        &quot;role&quot;: &quot;assistant&quot;,
        &quot;content&quot;: &quot;**String** is a fundamental data type in programming that represents a sequence of characters. It is a collection of characters enclosed within double quotes (\&quot;).\n\n**Characteristics of a String:**\n\n- Sequence of characters\n- Immutable (cannot be modified after creation)\n- Consists of characters, digits, or a combination of both\n- Can store both simple and complex data\n\n**Operations on Strings:**\n\n- **Length():** Returns the number of characters in a string.\n- **Index():** Returns the position of a character within a string.\n- **Substring():** Extracts a sub-sequence of characters from a string.\n- **Concat():** Combines multiple strings into a single string.\n- **Split():** Divides a string into multiple substrings based on a delimiter.\n\n**Syntax:**\n\n```\nstring = \&quot;Hello World!\&quot;\n```\n\n**Example Usage:**\n\n```python\nmy_string = \&quot;This is a string.\&quot;\n\n# Get the length of the string\nlength = len(my_string)\n\n# Print the first 5 characters of the string\nprint(my_string[:5])\n```\n\n**Benefits of Using Strings:**\n\n- **Data storage:** Efficient way to store and manage large amounts of text data.\n- **Communication:** Allows for the representation of human-readable data.\n- **Algorithm efficiency:** Strings are often used as keys in dictionaries and as input parameters for functions.\n- **Code readability:** Makes code more readable by using meaningful variable names and descriptive string literals.\n\n**Applications of Strings:**\n\n- Web development (HTML, CSS, JavaScript)\n- Data processing and analysis\n- Database management\n- System programming\n- Text manipulation and formatting\n\n**Additional Points:**\n\n- Strings are immutable, meaning their value cannot be changed after creation.\n- Strings can contain special characters and Unicode characters.\n- The type of a string is determined by the programming language or environment in which it is used.&quot;
      },
      &quot;logprobs&quot;: {
        &quot;text_offset&quot;: [],
        &quot;token_logprobs&quot;: [
          0,
          0
        ],
        &quot;tokens&quot;: [],
        &quot;top_logprobs&quot;: []
      }
    }
  ],
  &quot;usage&quot;: {
    &quot;prompt_tokens&quot;: 14,
    &quot;total_tokens&quot;: 420,
    &quot;completion_tokens&quot;: 406
  }
}
</code></pre>
<h2 id="shell">Shell<a class="headerlink" href="#shell" title="Permanent link">#</a></h2>
<h2 id="request_1">Request<a class="headerlink" href="#request_1" title="Permanent link">#</a></h2>
<pre><code>curl --request POST \
     --url https://integrate.api.nvidia.com/v1/chat/completions \
     --header 'accept: application/json' \
     --header 'authorization: Bearer xxxxxxxx' \
     --header 'content-type: application/json' \
     --data '
{
  &quot;model&quot;: &quot;google/gemma-2b&quot;,
  &quot;max_tokens&quot;: 1024,
  &quot;stream&quot;: false,
  &quot;temperature&quot;: 0.5,
  &quot;top_p&quot;: 1,
  &quot;stop&quot;: null,
  &quot;frequency_penalty&quot;: 0,
  &quot;presence_penalty&quot;: 0,
  &quot;seed&quot;: 0,
  &quot;messages&quot;: &quot;string&quot;
}
'
</code></pre>
<h2 id="models_1">Models<a class="headerlink" href="#models_1" title="Permanent link">#</a></h2>
<h2 id="google-codegemma-7b">google / codegemma-7b<a class="headerlink" href="#google-codegemma-7b" title="Permanent link">#</a></h2>
<p>CodeGemma is a family of lightweight open code models built on top of Gemma.CodeGemma models are text-to-text and text-to-code decoder-only models and are available as a 7 billion pretrained variant that specializes in code completion and code generation tasks, a 7 billion parameter instruction-tuned variant for code chat and instruction following and a 2 billion parameter pretrained variant
for fast code completion. This model is ready for commercial use.</p>
<p><a href="https://docs.api.nvidia.com/nim/reference/google-codegemma-7b">google / codegemma-7b Model</a>
<a href="https://docs.api.nvidia.com/nim/reference/google-codegemma-7b-infer">google / codegemma-7b Endpoint</a></p>
<h2 id="third-party-community-consideration_1">Third-Party Community Consideration<a class="headerlink" href="#third-party-community-consideration_1" title="Permanent link">#</a></h2>
<p>This model is not owned or developed by NVIDIA. This model has been developed and built to a third-party’s requirements for this application and use case; see link to the <a href="https://ai.google.dev/gemma/docs/codegemma">CodeGemma Model Card</a>.</p>
<p>Terms of Use
By accessing this model, you are agreeing to the NVIDIA AI Foundation Models Community License</p>
<p>Additional Information: Gemma Terms of Use, Google Prohibited Use Policy.</p>
<h2 id="resources-and-technical-documentation_1">Resources and Technical Documentation<a class="headerlink" href="#resources-and-technical-documentation_1" title="Permanent link">#</a></h2>
<p><a href="https://ai.google.dev/responsible">Responsible Generative AI Toolkit</a>
<a href="https://www.kaggle.com/models/google/codegemma">CodeGemma on Kaggle</a></p>
<h2 id="model-architecture">Model Architecture:<a class="headerlink" href="#model-architecture" title="Permanent link">#</a></h2>
<p>Architecture Type: Transformer Decoder Network</p>
<p>Network Architecture: Real-Gated Linear Recurrent Unit (RG-LRU)</p>
<h2 id="implementation-information_1">Implementation Information<a class="headerlink" href="#implementation-information_1" title="Permanent link">#</a></h2>
<p>Hardware and Frameworks used during training Like
Gemma, CodeGemma was trained on the latest generation of
Tensor Processing Unit (TPU)
hardware (TPUv5e),
using JAX and ML Pathways.</p>
<h2 id="evaluation-approach">Evaluation Approach<a class="headerlink" href="#evaluation-approach" title="Permanent link">#</a></h2>
<p>Code completion benchmarks: HumanEval (HE) Single Line and Multiple Line Infilling
Code generation benchmarks: HumanEval, MBPP, BabelCode (BC)
(C++, C#, Go, Java, JavaScript, Kotlin, Python, Rust)
Q&amp;A: BoolQ, PIQA, TriviaQA
Natural Language: ARC-Challenge, HellaSwag, MMLU, WinoGrande
Math Reasoning: GSM8K, MATH</p>
<h2 id="request_2">Request<a class="headerlink" href="#request_2" title="Permanent link">#</a></h2>
<pre><code>curl --request POST \
     --url https://integrate.api.nvidia.com/v1/chat/completions \
     --header 'accept: application/json' \
     --header 'authorization: Bearer nvapi-xxxxxx' \
     --header 'content-type: application/json' \
     --data '
{
  &quot;model&quot;: &quot;google/codegemma-7b&quot;,
  &quot;max_tokens&quot;: 1024,
  &quot;stream&quot;: false,
  &quot;temperature&quot;: 0.5,
  &quot;top_p&quot;: 1,
  &quot;stop&quot;: null,
  &quot;frequency_penalty&quot;: 0,
  &quot;presence_penalty&quot;: 0,
  &quot;seed&quot;: 0,
  &quot;messages&quot;: &quot;string&quot;
}
'
</code></pre>
<h2 id="response_1">Response<a class="headerlink" href="#response_1" title="Permanent link">#</a></h2>
<pre><code>{
  &quot;id&quot;: &quot;chatcmpl-6e1f3939-667c-46dc-bbd4-89c174aa5855&quot;,
  &quot;object&quot;: &quot;chat.completion&quot;,
  &quot;created&quot;: 1732297615,
  &quot;model&quot;: &quot;google/codegemma-7b&quot;,
  &quot;choices&quot;: [
    {
      &quot;index&quot;: 0,
      &quot;message&quot;: {
        &quot;role&quot;: &quot;assistant&quot;,
        &quot;content&quot;: &quot;**Definition:**\n\nA string is a sequence of characters enclosed in quotes. In Python, strings are immutable, meaning their contents cannot be changed after they are created.\n\n**Creating Strings:**\n\n* Single quotes: `'hello'`\n* Double quotes: `\&quot;hello\&quot;`\n* Triple quotes (for multi-line strings):\n    * `'''hello'''`\n    * `\&quot;\&quot;\&quot;hello\&quot;\&quot;\&quot;`\n\n**String Operations:**\n\n* Concatenation: `+` operator\n* Repetition: `*` operator\n* Slicing: `[]` operator\n* Indexing: accessing individual characters\n* Membership testing: `in` operator\n* String methods (e.g., `len()`, `upper()`, `lower()`, `split()`)\n\n**String Properties:**\n\n* Immutable\n* Ordered sequence of characters\n* Can contain any type of character (letters, numbers, symbols)\n\n**Examples:**\n\n```python\n# Create a string\nmessage = \&quot;Hello, world!\&quot;\n\n# Print the string\nprint(message)\n\n# Concatenate strings\ngreeting = \&quot;Greetings, \&quot; + message\n\n# Repeat a string\nrepeated_message = message * 3\n\n# Slice a string\nfirst_five_chars = message[:5]\n\n# Check if a character is in a string\nif 'w' in message:\n    print(\&quot;The letter 'w' is in the string.\&quot;)\n```\n\n**Additional Notes:**\n\n* Strings are case-sensitive.\n* Strings can be indexed and sliced using integer values.\n* There are several built-in functions and methods for working with strings.\n* Python also supports string formatting for creating formatted output.&quot;
      },
      &quot;logprobs&quot;: {
        &quot;text_offset&quot;: [],
        &quot;token_logprobs&quot;: [
          0,
          0
        ],
        &quot;tokens&quot;: [],
        &quot;top_logprobs&quot;: []
      }
    }
  ],
  &quot;usage&quot;: {
    &quot;prompt_tokens&quot;: 14,
    &quot;total_tokens&quot;: 361,
    &quot;completion_tokens&quot;: 347
  }
}
</code></pre>
<h2 id="model">Model<a class="headerlink" href="#model" title="Permanent link">#</a></h2>
<p><a href="https://docs.api.nvidia.com/nim/reference/google-gemma-2b">google / gemma-2b</a></p>
<p><a href="https://docs.api.nvidia.com/nim/reference/google-gemma-2-2b-it">google / gemma-2-2b-it</a></p>
<p><a href="https://docs.api.nvidia.com/nim/reference/google-gemma-2-9b-it">google / gemma-2-9b-it</a></p>
<p><a href="https://docs.api.nvidia.com/nim/reference/google-gemma-2-27b-it">google / gemma-2-27b-it</a></p>
<p><a href="https://docs.api.nvidia.com/nim/reference/google-codegemma-7b">google / codegemma-7b</a></p>
<p><a href="https://docs.api.nvidia.com/nim/reference/google-recurrentgemma-2b">google / recurrentgemma-2b</a></p>
<p><a href="https://docs.api.nvidia.com/nim/reference/google-shieldgemma-9b">google / shieldgemma-9b</a></p>
<h2 id="endpoint">Endpoint<a class="headerlink" href="#endpoint" title="Permanent link">#</a></h2>
<p><a href="https://docs.api.nvidia.com/nim/reference/google-gemma-2b-infer">Create chat completion (gemma-2b)</a></p>
<p><a href="https://docs.api.nvidia.com/nim/reference/google-gemma-2-2b-it-infer">Create chat completion (gemma-2-2b-it)</a></p>
<p><a href="https://docs.api.nvidia.com/nim/reference/google-gemma-2-9b-it-infer">Create chat completion (gemma-2-9b-it)</a></p>
<p><a href="https://docs.api.nvidia.com/nim/reference/google-gemma-2-27b-it-infer">Create chat completion (gemma-2-27b-it)</a></p>
<p><a href="https://docs.api.nvidia.com/nim/reference/google-codegemma-7b-infer">Create chat completion (codegemma-7b)</a></p>
<p><a href="https://docs.api.nvidia.com/nim/reference/google-recurrentgemma-2b-infer">Create chat completion (recurrentgemma-2b)</a></p>
<p><a href="https://docs.api.nvidia.com/nim/reference/google-shieldgemma-9b-infer">Create chat completion (shieldgemma-9b)</a></p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../deepseek/deepseek.html" class="btn btn-neutral float-left" title="deepseek"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../ibm/ibm.html" class="btn btn-neutral float-right" title="ibm">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/ganesh-document/all-documents" class="fa fa-code-fork" style="color: #fcfcfc"> Ganesh All Documents</a>
        </span>
    
    
      <span><a href="../deepseek/deepseek.html" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../ibm/ibm.html" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../../../../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../../../../..";</script>
    <script src="../../../../../js/theme_extra.js"></script>
    <script src="../../../../../js/theme.js"></script>
      <script src="../../../../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
